{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alIIEHibGc3M"
      },
      "source": [
        "## Part 1: Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "6eDUJ4NtGc3P",
        "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>...</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Sales</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>3</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Other</td>\n",
              "      <td>4</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
              "0   41       Yes      Travel_Rarely                   Sales                 1   \n",
              "1   49        No  Travel_Frequently  Research & Development                 8   \n",
              "2   37       Yes      Travel_Rarely  Research & Development                 2   \n",
              "3   33        No  Travel_Frequently  Research & Development                 3   \n",
              "4   27        No      Travel_Rarely  Research & Development                 2   \n",
              "\n",
              "   Education EducationField  EnvironmentSatisfaction  HourlyRate  \\\n",
              "0          2  Life Sciences                        2          94   \n",
              "1          1  Life Sciences                        3          61   \n",
              "2          2          Other                        4          92   \n",
              "3          4  Life Sciences                        4          56   \n",
              "4          1        Medical                        1          40   \n",
              "\n",
              "   JobInvolvement  ...  PerformanceRating RelationshipSatisfaction  \\\n",
              "0               3  ...                  3                        1   \n",
              "1               2  ...                  4                        4   \n",
              "2               2  ...                  3                        2   \n",
              "3               3  ...                  3                        3   \n",
              "4               3  ...                  3                        4   \n",
              "\n",
              "   StockOptionLevel TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
              "0                 0                 8                      0               1   \n",
              "1                 1                10                      3               3   \n",
              "2                 0                 7                      3               3   \n",
              "3                 0                 8                      3               3   \n",
              "4                 1                 6                      3               3   \n",
              "\n",
              "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
              "0               6                   4                        0   \n",
              "1              10                   7                        1   \n",
              "2               0                   0                        0   \n",
              "3               8                   7                        3   \n",
              "4               2                   2                        2   \n",
              "\n",
              "   YearsWithCurrManager  \n",
              "0                     5  \n",
              "1                     7  \n",
              "2                     0  \n",
              "3                     0  \n",
              "4                     2  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow import sparse\n",
        "\n",
        "#  Import and read the attrition data\n",
        "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
        "attrition_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g22aQSY4Gc3Q",
        "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Age                         43\n",
              "Attrition                    2\n",
              "BusinessTravel               3\n",
              "Department                   3\n",
              "DistanceFromHome            29\n",
              "Education                    5\n",
              "EducationField               6\n",
              "EnvironmentSatisfaction      4\n",
              "HourlyRate                  71\n",
              "JobInvolvement               4\n",
              "JobLevel                     5\n",
              "JobRole                      9\n",
              "JobSatisfaction              4\n",
              "MaritalStatus                3\n",
              "NumCompaniesWorked          10\n",
              "OverTime                     2\n",
              "PercentSalaryHike           15\n",
              "PerformanceRating            2\n",
              "RelationshipSatisfaction     4\n",
              "StockOptionLevel             4\n",
              "TotalWorkingYears           40\n",
              "TrainingTimesLastYear        7\n",
              "WorkLifeBalance              4\n",
              "YearsAtCompany              37\n",
              "YearsInCurrentRole          19\n",
              "YearsSinceLastPromotion     16\n",
              "YearsWithCurrManager        18\n",
              "dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "attrition_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "50vMgBEnJbfM"
      },
      "outputs": [],
      "source": [
        "# Create y_df with the Attrition and Department columns\n",
        "y_df = attrition_df[['Attrition', 'Department']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Virka0zLGc3R",
        "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Age                        int64\n",
              "NumCompaniesWorked         int64\n",
              "DistanceFromHome           int64\n",
              "Education                  int64\n",
              "TotalWorkingYears          int64\n",
              "YearsAtCompany             int64\n",
              "YearsSinceLastPromotion    int64\n",
              "YearsWithCurrManager       int64\n",
              "JobSatisfaction            int64\n",
              "WorkLifeBalance            int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a list of at least 10 column names to use as X data\n",
        "selected_columns = ['Age', 'NumCompaniesWorked', 'DistanceFromHome', 'Education', 'TotalWorkingYears', 'YearsAtCompany', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'JobSatisfaction', 'WorkLifeBalance']\n",
        "\n",
        "# Create X_df using your selected columns\n",
        "X_df = attrition_df[selected_columns]\n",
        "\n",
        "# Show the data types for X_df\n",
        "X_df.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KaJfdOGUMHMR"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYubUJqiLCSp",
        "outputId": "53f31721-571c-4c94-d13e-25a715749593"
      },
      "outputs": [],
      "source": [
        "# Convert your X data to numeric data types however you see fit\n",
        "X_train = tf.cast(X_train, tf.float32)\n",
        "X_test = tf.cast(X_test, tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EWA-aIA5Gc3T"
      },
      "outputs": [],
      "source": [
        "# # Create a StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "\n",
        "# # Fit the StandardScaler to the training data\n",
        "# X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# # Scale the training and testing data\n",
        "# X_train_scaled = X_scaler.transform(X_train)\n",
        "# X_test_scaled = X_scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z0Mky8vQSz4",
        "outputId": "debefc85-c20b-48f5-f4d9-91eadd65d36a"
      },
      "outputs": [],
      "source": [
        "# Create a OneHotEncoder for the Department column\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder()\n",
        "\n",
        "# Fit the encoder to the training data\n",
        "enc.fit(y_train[['Department']])\n",
        "\n",
        "# Create two new variables by applying the encoder to the training and testing data\n",
        "X_train_encoded = enc.transform(y_train[['Department']])\n",
        "X_test_encoded = enc.transform(y_test[['Department']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G4DSpvFRrk4",
        "outputId": "9842e948-8a55-4b80-8fac-f96714e85589"
      },
      "outputs": [],
      "source": [
        "# Create a OneHotEncoder for the Attrition column\n",
        "enc = OneHotEncoder()\n",
        "\n",
        "# Fit the encoder to the training data\n",
        "enc.fit(y_train[['Attrition']])\n",
        "\n",
        "# Create two new variables by applying the encoder to the training and testing data\n",
        "encoded_y_train = enc.transform(y_train[['Attrition']])\n",
        "encoded_y_test = enc.transform(y_test[['Attrition']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykNmu_WWGc3T"
      },
      "source": [
        "## Create, Compile, and Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WUptZqmSGc3T"
      },
      "outputs": [],
      "source": [
        "# Find the number of columns in the X training data\n",
        "n_cols = X_train_scaled.shape[1]\n",
        "\n",
        "# Create the input layer\n",
        "input_layer = layers.Input(shape=(n_cols,))\n",
        "\n",
        "# Create at least two shared layers\n",
        "shared_layer1 = layers.Dense(10, activation='relu')(input_layer)\n",
        "shared_layer2 = layers.Dense(10, activation='relu')(shared_layer1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JukjTm2yTEqd"
      },
      "outputs": [],
      "source": [
        "# Create a branch for Department with a hidden layer and an output layer\n",
        "department_hidden = layers.Dense(10, activation='relu')(shared_layer2)\n",
        "department_output = layers.Dense(3, activation='sigmoid', name='department')(department_hidden)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9OqhUiOJUBkR"
      },
      "outputs": [],
      "source": [
        "# Explicitly ensure it is dense and the correct data type\n",
        "attrition_dense_input = tf.convert_to_tensor(shared_layer2)\n",
        "attrition_dense_input = tf.cast(attrition_dense_input, dtype=tf.float32)\n",
        "\n",
        "# Then continue with your model definition\n",
        "attrition_hidden = layers.Dense(10, activation='relu')(attrition_dense_input)\n",
        "attrition_output = layers.Dense(2, activation='sigmoid', name='attrition')(attrition_hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twmuejdxGc3T",
        "outputId": "25096308-b68b-42e4-e4ea-ae82e97c435a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 10)]                 0         []                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10)                   110       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 10)                   110       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor (TFOp  (None, 10)                   0         ['dense_1[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.cast (TFOpLambda)        (None, 10)                   0         ['tf.convert_to_tensor[0][0]']\n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 10)                   110       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 10)                   110       ['tf.cast[0][0]']             \n",
            "                                                                                                  \n",
            " department (Dense)          (None, 3)                    33        ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " attrition (Dense)           (None, 2)                    22        ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 495 (1.93 KB)\n",
            "Trainable params: 495 (1.93 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create the model\n",
        "model = Model(inputs=input_layer, outputs=[department_output, attrition_output])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss={'department': 'categorical_crossentropy', 'attrition': 'categorical_crossentropy'}, metrics=['accuracy'])\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "Value for attr 'TI' of double is not in the list of allowed values: uint8, int8, int32, int64\n\t; NodeDef: {{node OneHot}}; Op<name=OneHot; signature=indices:TI, depth:int32, on_value:T, off_value:T -> output:T; attr=axis:int,default=-1; attr=T:type; attr=TI:type,default=DT_INT64,allowed=[DT_UINT8, DT_INT8, DT_INT32, DT_INT64]> [Op:OneHot] name: ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m encoded_y_test_dense \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mto_dense(encoded_y_test_sparse)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Convert dense tensors to one-hot encoded tensors\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m encoded_y_train_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_y_train_dense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m encoded_y_test_one_hot \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(encoded_y_test_dense, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Evaluate the model with the testing data\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Value for attr 'TI' of double is not in the list of allowed values: uint8, int8, int32, int64\n\t; NodeDef: {{node OneHot}}; Op<name=OneHot; signature=indices:TI, depth:int32, on_value:T, off_value:T -> output:T; attr=axis:int,default=-1; attr=T:type; attr=TI:type,default=DT_INT64,allowed=[DT_UINT8, DT_INT8, DT_INT32, DT_INT64]> [Op:OneHot] name: "
          ]
        }
      ],
      "source": [
        "# Convert scipy sparse matrices to TensorFlow SparseTensors\n",
        "encoded_y_train_sparse = tf.sparse.from_dense(encoded_y_train.todense())\n",
        "encoded_y_test_sparse = tf.sparse.from_dense(encoded_y_test.todense())\n",
        "\n",
        "# Convert SparseTensors to dense tensors\n",
        "encoded_y_train_dense = tf.sparse.to_dense(encoded_y_train_sparse)\n",
        "encoded_y_test_dense = tf.sparse.to_dense(encoded_y_test_sparse)\n",
        "\n",
        "# Convert dense tensors to one-hot encoded tensors\n",
        "encoded_y_train_one_hot = tf.one_hot(encoded_y_train_dense, depth=2)\n",
        "encoded_y_test_one_hot = tf.one_hot(encoded_y_test_dense, depth=2)\n",
        "\n",
        "# Evaluate the model with the testing data\n",
        "model_loss, model_accuracy = model.evaluate(\n",
        "    X_test_scaled,\n",
        "    {\n",
        "        \"department\": X_test_encoded,\n",
        "        \"attrition\": encoded_y_test_one_hot,\n",
        "    },\n",
        "    verbose=2,\n",
        ")\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8oGy0dpGc3U",
        "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/backend.py\", line 5571, in categorical_crossentropy\n        target = tf.convert_to_tensor(target)\n\n    TypeError: Failed to convert elements of SparseTensor(indices=Tensor(\"DeserializeSparse_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse_1:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack_1:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdepartment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattrition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_y_train\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/var/folders/s5/83_c6qwd24vgpy6ybcz6q4ww0000gn/T/__autograph_generated_filegumi94de.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/backend.py\", line 5571, in categorical_crossentropy\n        target = tf.convert_to_tensor(target)\n\n    TypeError: Failed to convert elements of SparseTensor(indices=Tensor(\"DeserializeSparse_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse_1:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack_1:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train_scaled, {'department': encoded_y_train, 'attrition': encoded_y_train}, epochs=100, shuffle=True, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsMoaQlgGc3U",
        "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1919, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/backend.py\", line 5722, in sparse_categorical_crossentropy\n        target = tf.convert_to_tensor(target)\n\n    TypeError: Failed to convert elements of SparseTensor(indices=Tensor(\"DeserializeSparse_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse_1:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack_1:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model with the testing data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_loss, model_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdepartment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_y_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattrition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_y_test\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/var/folders/s5/83_c6qwd24vgpy6ybcz6q4ww0000gn/T/__autograph_generated_filek20_a56u.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1919, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"/Users/jake/anaconda3/envs/scikit_dev/lib/python3.10/site-packages/keras/src/backend.py\", line 5722, in sparse_categorical_crossentropy\n        target = tf.convert_to_tensor(target)\n\n    TypeError: Failed to convert elements of SparseTensor(indices=Tensor(\"DeserializeSparse_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse_1:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack_1:0\", shape=(2,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model with the testing data\n",
        "model_loss, model_accuracy = model.evaluate(X_test_scaled, {'department': encoded_y_test, 'attrition': encoded_y_test}, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlCtlHi0Vt54",
        "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model_accuracy' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Print the accuracy for both department and attrition\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDepartment Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel_accuracy\u001b[49m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Attrition Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_accuracy[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_accuracy' is not defined"
          ]
        }
      ],
      "source": [
        "# Print the accuracy for both department and attrition\n",
        "print(f\"Department Accuracy: {model_accuracy[1]}, Attrition Accuracy: {model_accuracy[2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGSyfsZfWOQM"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In the provided space below, briefly answer the following questions.\n",
        "\n",
        "1. Is accuracy the best metric to use on this data? Why or why not?\n",
        "\n",
        "2. What activation functions did you choose for your output layers, and why?\n",
        "\n",
        "3. Can you name a few ways that this model might be improved?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi9SLpFnWvbF"
      },
      "source": [
        "YOUR ANSWERS HERE\n",
        "\n",
        "1. \n",
        "2. \n",
        "3. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
